{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install underthesea\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJF1eXAMA3hY",
        "outputId": "9a158ede-dbf2-4103-adca-e3f6842945c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting underthesea\n",
            "  Downloading underthesea-6.8.4-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from underthesea) (8.2.1)\n",
            "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
            "  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from underthesea) (3.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from underthesea) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from underthesea) (2.32.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.6.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from underthesea) (6.0.2)\n",
            "Collecting underthesea-core==1.0.4 (from underthesea)\n",
            "  Downloading underthesea_core-1.0.4-cp311-cp311-manylinux2010_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->underthesea) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (2025.6.15)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (3.6.0)\n",
            "Downloading underthesea-6.8.4-py3-none-any.whl (20.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading underthesea_core-1.0.4-cp311-cp311-manylinux2010_x86_64.whl (657 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.11 underthesea-6.8.4 underthesea-core-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NWcYPO2GwqM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from underthesea import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# CONFIG: Bá»™ keywords lÃ½ do churn\n",
        "# -----------------------------\n",
        "\n",
        "CHURN_KEYWORDS = {\n",
        "    'bug': ['bug', 'lá»—i', 'crash', 'sáº­p', 'Ä‘Æ¡', 'treo'],\n",
        "    'lag': ['lag', 'giáº­t', 'cháº­m', 'disconnect', 'delay', 'ping cao', 'máº¥t káº¿t ná»‘i', 'server lá»—i'],\n",
        "    'ads': ['quáº£ng cÃ¡o', 'ads'],\n",
        "    'update': [\n",
        "        'update', 'cáº­p nháº­t', 'báº¯t update', 'táº£i láº¡i', 'dung lÆ°á»£ng',\n",
        "        'dung lÆ°á»£ng lá»›n', 'náº·ng mÃ¡y', 'náº·ng', 'full gb', 'quÃ¡ náº·ng', 'chiáº¿m bá»™ nhá»›'\n",
        "    ],\n",
        "    'price': ['Ä‘áº¯t', 'mua', 'náº¡p', 'tiá»n', 'náº¡p tháº»'],\n",
        "    'toxic': [\n",
        "        'toxic', 'tráº©u', 'phÃ¡ game', 'afk', 'feed', 'chá»­i', 'team ngu',\n",
        "        'tráº» trÃ¢u', 'phÃ¡ tráº­n', 'tá»‘ cÃ¡o', 'bus báº©n', 'gáº¡', 'quáº¥y rá»‘i'\n",
        "    ],\n",
        "    'hack': [\n",
        "        'hack', 'cheat', 'tool', 'bug map', 'mod', 'hack map',\n",
        "        'buff elo', 'ddos', 'gian láº­n'\n",
        "    ],\n",
        "    'matchmaking': [\n",
        "        'ghÃ©p tráº­n', 'matchmaking', 'ghÃ©p team', 'ghÃ©p rank', 'thuáº­t toÃ¡n',\n",
        "        'team ngu', 'rank lá»—i', 'kda sai', 'tÃ­nh kda', 'trá»« uy tÃ­n',\n",
        "        'sÃ©t rank', 'reset rank', 'elo', 'ghÃ©p ngáº«u nhiÃªn'\n",
        "    ],\n",
        "    'performance': ['cháº­m', 'giáº­t', 'lag', 'náº·ng', 'thiáº¿t bá»‹ yáº¿u', 'yáº¿u mÃ¡y'],\n",
        "    'forced_pick': ['chá»n gÃ¬ pháº£i chÆ¡i Ä‘Ã³', 'tÃ­nh nÄƒng má»›i', 'báº¯t buá»™c', 'Ã©p buá»™c', 'meta', 'bá»‹ Ã©p pick'],\n",
        "    'trash': ['rÃ¡c', 'trash', 'tá»‡', 'cá»©c', 'quÃ¡ chÃ¡n', 'quÃ¡ tá»‡', 'vá»©t Ä‘i', 'vÃ´ dá»¥ng']\n",
        "}"
      ],
      "metadata": {
        "id": "NvERDJXxA8NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# UTILS: CÃ¡c hÃ m xá»­ lÃ½\n",
        "# -----------------------------\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    LÃ m sáº¡ch review:\n",
        "    - lowercase\n",
        "    - bá» sá»‘, dáº¥u cÃ¢u, khoáº£ng tráº¯ng thá»«a\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "def tokenize_vi(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Tokenize tiáº¿ng Viá»‡t báº±ng underthesea\n",
        "    \"\"\"\n",
        "    return word_tokenize(text, format=\"text\")\n",
        "\n",
        "\n",
        "def detect_sentiment(score: int) -> str:\n",
        "    \"\"\"\n",
        "    Sentiment rule:\n",
        "    - score < 3: Negative\n",
        "    - score = 3: Neutral\n",
        "    - score > 3: Positive\n",
        "    \"\"\"\n",
        "    if score < 3:\n",
        "        return 'Negative'\n",
        "    elif score == 3:\n",
        "        return 'Neutral'\n",
        "    return 'Positive'\n",
        "\n",
        "\n",
        "def detect_churn_reason(text: str, score: int, keywords_dict: dict) -> str:\n",
        "    \"\"\"\n",
        "    Detect churn_reason:\n",
        "    - Náº¿u match keywords: tráº£ vá» nhÃ³m match\n",
        "    - Náº¿u khÃ´ng match nhÆ°ng score < 3: tráº£ vá» 'other'\n",
        "    - Náº¿u khÃ´ng match & khÃ´ng tiÃªu cá»±c: tráº£ vá» 'none'\n",
        "    \"\"\"\n",
        "    reasons = []\n",
        "    for reason, keywords in keywords_dict.items():\n",
        "        for kw in keywords:\n",
        "            if kw in text:\n",
        "                reasons.append(reason)\n",
        "                break\n",
        "\n",
        "    if reasons:\n",
        "        return ', '.join(sorted(set(reasons)))\n",
        "    if score < 3:\n",
        "        return 'other'\n",
        "    return 'none'\n"
      ],
      "metadata": {
        "id": "kiC2Q8ANAqzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# MAIN PIPELINE\n",
        "# -----------------------------\n",
        "\n",
        "def enrich_reviews(input_file: str, output_file: str) -> None:\n",
        "    \"\"\"\n",
        "    Pipeline Ä‘áº§y Ä‘á»§:\n",
        "    - Load CSV\n",
        "    - Clean, tokenize\n",
        "    - GÃ¡n sentiment\n",
        "    - Detect churn_reason\n",
        "    - Xuáº¥t file enrich\n",
        "    - In sample má»—i bÆ°á»›c\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(input_file)\n",
        "    print(f\"âœ… Loaded: {df.shape[0]} rows | {df.shape[1]} columns\")\n",
        "    print(df.head(3)[['user_name', 'review_text', 'score']])\n",
        "\n",
        "    # 1. Chuyá»ƒn review_date\n",
        "    df['review_date'] = pd.to_datetime(df['review_date'])\n",
        "    print(\"\\nâœ… Converted `review_date`:\")\n",
        "    print(df[['review_date']].head(3))\n",
        "\n",
        "    # 2. Clean text\n",
        "    df['clean_review'] = df['review_text'].astype(str).apply(clean_text)\n",
        "    print(\"\\nâœ… Cleaned `review_text`:\")\n",
        "    print(df[['review_text', 'clean_review']].head(3))\n",
        "\n",
        "    # 3. Tokenize\n",
        "    df['tokens'] = df['clean_review'].apply(tokenize_vi)\n",
        "    print(\"\\nâœ… Tokenized text:\")\n",
        "    print(df[['clean_review', 'tokens']].head(3))\n",
        "\n",
        "    # 4. Sentiment\n",
        "    df['sentiment'] = df['score'].apply(detect_sentiment)\n",
        "    print(\"\\nâœ… Sentiment:\")\n",
        "    print(df[['score', 'sentiment']].head(3))\n",
        "\n",
        "    # 5. Churn Reason\n",
        "    df['churn_reason'] = df.apply(\n",
        "        lambda row: detect_churn_reason(row['clean_review'], row['score'], CHURN_KEYWORDS),\n",
        "        axis=1\n",
        "    )\n",
        "    print(\"\\nâœ… Churn Reason:\")\n",
        "    print(df[['clean_review', 'churn_reason']].head(5))\n",
        "\n",
        "    # 6. Save\n",
        "    df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
        "    print(f\"\\nâœ… Pipeline DONE! File enrich Ä‘Ã£ lÆ°u: {output_file}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    enrich_reviews(\n",
        "        input_file=\"lien_quan_mobile_filtered_latest_versions.csv\",\n",
        "        output_file=\"lien_quan_mobile_churn_enriched.csv\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeqq6bjGAq1V",
        "outputId": "4c881261-97a1-4d23-db50-33da3d4148b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded: 7470 rows | 8 columns\n",
            "       user_name                                     review_text  score\n",
            "0  ThÃ¡i ThÃ nh Jr  Game cáº­p nháº­t nhÆ° cá»©c, láº¡i pháº£i táº£i láº¡i táº¥t cáº£      1\n",
            "1      Giang BÃ¹i                                    Game hay ğŸ˜ŠğŸ˜ŠğŸ˜Š      5\n",
            "2       Chau Bui                                  ko nÃ³i nÃªn lá»i      1\n",
            "\n",
            "âœ… Converted `review_date`:\n",
            "          review_date\n",
            "0 2025-07-10 14:27:01\n",
            "1 2025-07-10 14:26:30\n",
            "2 2025-07-10 14:25:52\n",
            "\n",
            "âœ… Cleaned `review_text`:\n",
            "                                      review_text  \\\n",
            "0  Game cáº­p nháº­t nhÆ° cá»©c, láº¡i pháº£i táº£i láº¡i táº¥t cáº£   \n",
            "1                                    Game hay ğŸ˜ŠğŸ˜ŠğŸ˜Š   \n",
            "2                                  ko nÃ³i nÃªn lá»i   \n",
            "\n",
            "                                    clean_review  \n",
            "0  game cáº­p nháº­t nhÆ° cá»©c láº¡i pháº£i táº£i láº¡i táº¥t cáº£  \n",
            "1                                   game hay ğŸ˜ŠğŸ˜ŠğŸ˜Š  \n",
            "2                                 ko nÃ³i nÃªn lá»i  \n",
            "\n",
            "âœ… Tokenized text:\n",
            "                                    clean_review  \\\n",
            "0  game cáº­p nháº­t nhÆ° cá»©c láº¡i pháº£i táº£i láº¡i táº¥t cáº£   \n",
            "1                                   game hay ğŸ˜ŠğŸ˜ŠğŸ˜Š   \n",
            "2                                 ko nÃ³i nÃªn lá»i   \n",
            "\n",
            "                                          tokens  \n",
            "0  game cáº­p_nháº­t nhÆ° cá»©c láº¡i pháº£i táº£i láº¡i táº¥t_cáº£  \n",
            "1                                 game hay ğŸ˜Š_ğŸ˜Š ğŸ˜Š  \n",
            "2                                 ko nÃ³i nÃªn lá»i  \n",
            "\n",
            "âœ… Sentiment:\n",
            "   score sentiment\n",
            "0      1  Negative\n",
            "1      5  Positive\n",
            "2      1  Negative\n",
            "\n",
            "âœ… Churn Reason:\n",
            "                                    clean_review              churn_reason\n",
            "0  game cáº­p nháº­t nhÆ° cá»©c láº¡i pháº£i táº£i láº¡i táº¥t cáº£             trash, update\n",
            "1                                   game hay ğŸ˜ŠğŸ˜ŠğŸ˜Š                      none\n",
            "2                                 ko nÃ³i nÃªn lá»i                     other\n",
            "3                                          vuiiu                      none\n",
            "4                          cáº­p nháº­t xong lag quÃ¡  lag, performance, update\n",
            "\n",
            "âœ… Pipeline DONE! File enrich Ä‘Ã£ lÆ°u: lien_quan_mobile_churn_enriched.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xs1ajUL-Aq3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lm_H4ECsAq5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L6FGEzhKAq78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qkbe0_XzAq94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pXnh0zcTArBT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}